{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7232f69-2535-45ef-8c72-64229ea44b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-27 22:02:07.045293: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-27 22:02:07.062351: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745791327.083502   95470 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745791327.090029   95470 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-27 22:02:07.112018: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import glob\n",
    "import spacy\n",
    "import pickle\n",
    "import random\n",
    "import difflib\n",
    "import textwrap\n",
    "import datetime\n",
    "import jsonlines\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils.shared_configs import LLAMA_MODEL_PATH, ZEHPYR_MODEL_PATH, get_sampling_params, initialize_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a5ffef-8be0-4479-94f7-beaf24884b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = initialize_llm(model_path=LLAMA_MODEL_PATH, tokenizer_path=LLAMA_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff29f936-c855-4405-8869-6ec7c649d0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_params = get_sampling_params(max_tokens=300, temperature=0.6, top_p=0.9, stops=[\"</s>\", \"\\n}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0e1e255c-9b59-4506-8dbd-2623805426ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f\"outputs/pointwise/pointwise_iteration_curr/pointwise_sed_outputs.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "#     pointwise_sed_outputs=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0694478a-c21b-40ee-9f7b-e84a3f3d9aa9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# entity = pointwise_sed_outputs[0]['entities'][0]\n",
    "# entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "046b47fb-369e-4b47-85f6-7690cb7e2456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 11 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Unnamed: 0           100 non-null    int64  \n",
      " 1   article_text         100 non-null    object \n",
      " 2   date                 100 non-null    object \n",
      " 3   article_title        100 non-null    object \n",
      " 4   entity_title         100 non-null    object \n",
      " 5   entity_salience      100 non-null    int64  \n",
      " 6   offsets              100 non-null    object \n",
      " 7   url                  100 non-null    object \n",
      " 8   surrounding_context  100 non-null    object \n",
      " 9   gt_wiki_id           99 non-null     float64\n",
      " 10  candidates           95 non-null     object \n",
      "dtypes: float64(1), int64(2), object(8)\n",
      "memory usage: 8.7+ KB\n"
     ]
    }
   ],
   "source": [
    "wn_val_subset = pd.read_csv('wn_val_subset_4_27_pointwise_results.csv')\n",
    "wn_val_subset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69481891-c31d-47ea-919e-6f79d940fc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "COT_POOL = [\n",
    "    {\n",
    "        \"mention\": \"Apple\",\n",
    "        \"left_context\": \"Tim Cook is the CEO of\",\n",
    "        \"right_context\": \"which released the iPhone 15.\",\n",
    "        \"candidates\": [\n",
    "            {\"id\": 1, \"name\": \"Apple Inc.\", \"summary\": \"An American consumer‑electronics company.\"},\n",
    "            {\"id\": 2, \"name\": \"Apple (fruit)\", \"summary\": \"An edible fruit.\"},\n",
    "        ],\n",
    "        \"answer\": \"1.Apple Inc.\"\n",
    "    },\n",
    "    {\n",
    "        \"mention\": \"Jaguar\",\n",
    "        \"left_context\": \"He bought a new\",\n",
    "        \"right_context\": \"to replace his old sedan.\",\n",
    "        \"candidates\": [\n",
    "            {\"id\": 9, \"name\": \"Jaguar Cars\", \"summary\": \"A British luxury‑car brand.\"},\n",
    "            {\"id\": 8, \"name\": \"Jaguar (animal)\", \"summary\": \"A large cat native to the Americas.\"},\n",
    "        ],\n",
    "        \"answer\": \"9.Jaguar Cars\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2236243-6787-4065-84f8-db2f809441b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "    INSTRUCTION_PROMPT = \"1. Context: Look at the surrounding text to understand the topic.\\n2. Categories: Consider the type of the entity (person, organization, location, etc.).\\n3. Modifiers: Pay attention to words or phrases that add details to the mention.\\n4. Co-references: Check other mentions of the same entity in the text.\\n5. Temporal and Geographical Factors: Consider when and where the text was written.\\n6. External Knowledge: Use knowledge from outside the text.\\nRemember, effective entity disambiguation requires understanding the text thoroughly, having world knowledge, and exercising good judgment.\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f4661c0-cbf9-4254-add1-42fac7f040bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contextual_el_prompt(entity, candidates, CoT_POOL=COT_POOL, INSTRUCTION_PROMPT=INSTRUCTION_PROMPT):\n",
    "    ex = random.choice(COT_POOL)\n",
    "    \n",
    "    # CoT exemplar\n",
    "    ex_ctx = f\"{ex['left_context']} ###{ex['mention']}### {ex['right_context']}\"\n",
    "    ex_block = textwrap.dedent(f\"\"\"\\\n",
    "        The following example illustrates the task:\n",
    "        Mention: {ex['mention']}\n",
    "        Context: {ex_ctx}\n",
    "        Candidates: {ex['candidates']}\n",
    "        Answer: {ex['answer']}\"\"\")\n",
    "    \n",
    "    # create candidate map for later reconcilation\n",
    "    # cand_map, target_lines = {}, []\n",
    "    # for idx, cand in enumerate(random.sample(entity['candidates'], len(entity['candidates'])), 1):\n",
    "    #     cand_map[idx] = cand\n",
    "    #     target_lines.append(f\"Entity {idx}: {cand['cand_name']}. {cand['cand_summary']}\")\n",
    "    label_map = {}                         # label → candidate‑dict\n",
    "    cand_lines = []\n",
    "    for lbl, cand in enumerate(random.sample(entity['candidates'], len(entity['candidates'])), 1):\n",
    "        cand_lines.append(f\"{lbl}. {cand['cand_name']} – {cand['cand_summary']}\")\n",
    "        label_map[lbl] = cand              # store mapping\n",
    "        cand['prompt_label'] = lbl         # optional: keep inside dict\n",
    "\n",
    "    tgt_ctx = (entity['left_context'].strip() + ' ###' + entity['entity_title'] + '### ' + entity['right_context'].strip())\n",
    "    tgt_cand_lines = []\n",
    "    for idx, cand in enumerate(random.sample(entity['candidates'], len(entity['candidates'])), 1):\n",
    "        tgt_cand_lines.append(f\"{idx}. {cand['cand_name']} – {cand['cand_summary']}\")\n",
    "\n",
    "    tgt_block = textwrap.dedent(f\"\"\"\\\n",
    "        Now I will give you a new mention, its context, and a list of candidate entities.\n",
    "        The mention is highlighted with '###'.\n",
    "\n",
    "        Mention: {entity['entity_title']}\n",
    "        Context: {tgt_ctx}\n",
    "        {'; '.join(tgt_cand_lines)}\n",
    "\n",
    "        Think step by step.  At the end output exactly one line with the ID\n",
    "        and name of the chosen entity, e.g.  '3.Barack Obama'.\n",
    "        If none fit, output '-1.None'.\n",
    "    \"\"\")\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "        <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "        {SYSTEM_PROMPT}<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "        {INSTRUCTION_PROMPT}{ex_block}{tgt_block}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "        \"\"\".strip()\n",
    "    \n",
    "    return prompt.strip(), label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "51a35c3a-3c1c-4aaf-91ce-388ae4b3ac09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 731 prompts (last = (272, 6))\n"
     ]
    }
   ],
   "source": [
    "MAX_PROMPTS = 7500\n",
    "# (art_idx, ent_idx, cand_map, prompt)\n",
    "cx_prompt_records = []\n",
    "count=0\n",
    "for art_idx, art in enumerate(pointwise_sed_outputs):\n",
    "    for ent_idx, ent in enumerate(art[\"entities\"]):\n",
    "        if not ent.get(\"candidates\"):\n",
    "            count+=1\n",
    "            continue\n",
    "\n",
    "        if len(cx_prompt_records) >= MAX_PROMPTS:\n",
    "            break\n",
    "\n",
    "        prompt, cmap = contextual_el_prompt(ent, ent.get(\"candidates\"))\n",
    "        cx_prompt_records.append((art_idx, ent_idx, cmap, prompt))\n",
    "\n",
    "    if len(cx_prompt_records) >= MAX_PROMPTS:\n",
    "        break\n",
    "        \n",
    "print(f\"Collected {len(cx_prompt_records)} prompts \"\n",
    "      f\"(last = {cx_prompt_records[-1][:2]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "12110aa7-0092-4fa9-b6e2-d0616b0884dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26529"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3db28cb3-eb09-46dc-a861-582dd8c0ed27",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " 0,\n",
       " {1: {'mention': 'United States',\n",
       "   'cand_name': 'United States',\n",
       "   'cand_summary': \"The United States of America is a federal republic and representative democracy, comprising 50 states, five major self-governing territories, and various possessions, with an estimated population of over 327 million people, the third most populous country in the world, and a highly developed country with the world's largest economy by nominal GDP, second-largest by purchasing power parity, and a leading political, cultural, and scientific force internationally.\",\n",
       "   'cand_text': \"The United States of America (USA), commonly known as the United States (U.S. or US) or simply America, is a country comprising 50 states, a federal district, five major self-governing territories, and various possessions. At 3.8&nbsp;million square miles (9.8&nbsp;million km<sup>2</sup>), it is the world's third or fourth largest country by total area and is slightly smaller than the entire continent of Europe. Most of the country is located in central North America between Canada and Mexico. With an estimated population of over 327&nbsp;million people, the U.S. is the third most populous country. The capital is Washington, D.C., and the most populous city is New York City. Paleo-Indians migrated from Siberia to the North American mainland at least 12,000 years ago. European colonization began in the 16th century. The United States emerged from the thirteen British colonies established along the East Coast. Numerous disputes between Great Britain and the colonies led to the American Revolutionary War lasting between 1775 and 1783, leading to independence.<br /></ref> The United States embarked on a vigorous expansion across North America throughout the 19th century, gradually acquiring new territories, displacing Native Americans, and admitting new states until spanning the continent by 1848. During the second half of the 19th century, the American Civil War led to the abolition of slavery in the United States. The Spanish–American War and confirmed the country's status as a global military power. The United States emerged from as a global superpower. It was the first country to develop nuclear weapons, and the only one to use them in warfare. During the Cold War, the United States and the Soviet Union competed in the Space Race, culminating with the 1969 Apollo 11 mission, the spaceflight that first landed humans on the Moon. The end of the Cold War and collapse of the Soviet Union in 1991 left the United States as the world's sole superpower.<br /><br /><br /><br /></ref> The United States is a federal republic and a representative democracy. It is a founding member of the United Nations, World Bank, International Monetary Fund, Organization of American States (OAS), NATO, and other international organizations. It is a permanent member of the United Nations Security Council. A highly developed country, the United States is the world's largest economy by nominal GDP, the second-largest by purchasing power parity, and accounts for approximately a quarter of global GDP. The United States is the world's largest importer and the second-largest exporter of goods, by value. Although its population is 4% of the world total, it holds 31% of the total wealth in the world, the largest share of global wealth concentrated in a single country. Despite income and wealth disparities, the United States continues to rank very high in measures of socioeconomic performance, including average wage, , , human development, per capita GDP, and worker productivity. It is the foremost military power in the world, making up a third of global military spending, and is a leading political, cultural, and scientific force internationally.<br /><br /><br /></ref>\",\n",
       "   'id': 2,\n",
       "   'cand_wiki_id': '3434750',\n",
       "   'weighted_score': 1.0,\n",
       "   'llm_decision': ' Final Decision: yes\\n\\nI determined that the information is not sufficient to establish a relationship because the mention and the candidate entity have different roles in the text.\\n\\nThe mention is the capital of the United States, while the candidate entity is the country itself. Although the candidate entity is the country that the mention is the capital of, the mention and the candidate entity are not the same entity, but rather a different type of entity. This is a classic case of disambiguation, where the same name is used for different entities. In this case, the mention is a location, and the candidate entity is a country.',\n",
       "   'relevant': True,\n",
       "   'prompt_label': 1}},\n",
       " \"<|begin_of_text|><|start_header_id|>system<|end_header_id|> 1. Context: Look at the surrounding text to understand the topic.\\n2. Categories: Consider the type of the entity (person, organization, location, etc.).\\n3. Modifiers: Pay attention to words or phrases that add details to the mention.\\n4. Co-references: Check other mentions of the same entity in the text.\\n5. Temporal and Geographical Factors: Consider when and where the text was written.\\n6. External Knowledge: Use knowledge from outside the text.\\nRemember, effective entity disambiguation requires understanding the text thoroughly, having world knowledge, and exercising good judgment.\\n <|eot_id|><|start_header_id|>user<|end_header_id|> The following example illustrates the task:\\nMention: Apple\\nContext: Tim Cook is the CEO of ###Apple### which released the iPhone 15.\\nCandidates: [{'id': 1, 'name': 'Apple Inc.', 'summary': 'An American consumer‑electronics company.'}, {'id': 2, 'name': 'Apple (fruit)', 'summary': 'An edible fruit.'}]\\nAnswer: 1.Apple Inc.Now I will give you a new mention, its context, and a list of candidate entities.\\nThe mention is highlighted with '###'.\\n\\nMention: United States\\nContext: The ###United States### capital of Washington, D.C. legalized same-sex marriage on Wednesday. Beginning\\n1. United States – The United States of America is a federal republic and representative democracy, comprising 50 states, five major self-governing territories, and various possessions, with an estimated population of over 327 million people, the third most populous country in the world, and a highly developed country with the world's largest economy by nominal GDP, second-largest by purchasing power parity, and a leading political, cultural, and scientific force internationally.\\n\\nThink step by step.  At the end output exactly one line with the ID\\nand name of the chosen entity, e.g.  '3.Barack Obama'.\\nIf none fit, output '-1.None'.\\n <|eot_id|><|start_header_id|>assistant<|end_header_id|>\")"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cx_prompt_records[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b6bf80bc-150e-45b2-84e3-ee79d2cc1a6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 731/731 [02:32<00:00,  4.80it/s, est. speed input: 2987.28 toks/s, output: 1139.74 toks/s]\n"
     ]
    }
   ],
   "source": [
    "outputs = llm.generate(prompts=prompts, sampling_params=sampling_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "359fd47b-4d16-4600-8868-ec0f36fd4dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer_pat = re.compile(r'(-?\\d+)\\s*\\.(.+)')  \n",
    "# for rec, out in zip(cx_prompt_records, outputs):\n",
    "#     art_idx, ent_idx, cmap, _ = rec\n",
    "#     text = out.outputs[0].text.strip()\n",
    "\n",
    "#     # --- grab the first \"<id>.<name>\" we see (top‑to‑bottom)\n",
    "#     m = answer_pat.search(text)\n",
    "#     if not m:\n",
    "#         chosen_id = -1\n",
    "#     else:\n",
    "#         chosen_id = int(m.group(1))\n",
    "\n",
    "#     # --- write back\n",
    "#     ent = pointwise_sed_outputs[art_idx][\"entities\"][ent_idx]\n",
    "#     if chosen_id in cmap:                   # LLM picked a valid label\n",
    "#         ent[\"candidates\"] = [cmap[chosen_id]]\n",
    "#         ent[\"linker_response\"] = text       # (optional, for inspection)\n",
    "#     else:                                   # -1.None  or invalid label\n",
    "#         ent[\"candidates\"] = []\n",
    "#         ent[\"linker_response\"] = text\n",
    "\n",
    "answer_pat = re.compile(r'(-?\\d+)\\s*\\.\\s*(.+)', re.I)   # e.g.  3.Barack Obama\n",
    "\n",
    "for record, output in zip(cx_prompt_records, outputs):\n",
    "    art_idx, ent_idx, label_map, _ = record\n",
    "    ent   = pointwise_sed_outputs[art_idx][\"entities\"][ent_idx]\n",
    "\n",
    "    # raw text\n",
    "    linker_resp = output.outputs[0].text.strip()\n",
    "    ent[\"linker_response\"] = linker_resp\n",
    "\n",
    "    # default: no prediction\n",
    "    ent[\"top_linked_entity\"] = None\n",
    "\n",
    "    # grab the last non‑empty line and parse \"<label>.<name>\"\n",
    "    lines = [ln.strip() for ln in linker_resp.splitlines() if ln.strip()]\n",
    "    m     = answer_pat.search(lines[-1]) if lines else None\n",
    "    if not m:                         # failed to parse → leave None\n",
    "        continue\n",
    "\n",
    "    lbl = int(m.group(1))\n",
    "    if lbl < 0 or lbl not in label_map:\n",
    "        continue                      # \"-1.None\" or invalid label\n",
    "\n",
    "    cand = label_map[lbl]             # candidate dict chosen by the model\n",
    "    ent[\"top_linked_entity\"] = {\n",
    "        \"cand_name\":    cand[\"cand_name\"],\n",
    "        \"cand_wiki_id\": cand[\"cand_wiki_id\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9bffac35-83ff-48ef-82e6-238fb0111a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"outputs/pointwise/pointwise_iteration_curr/contextual_el_sed_outputs_v2.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(pointwise_sed_outputs, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "341335dc-743b-4946-827e-3850f0830dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities evaluated : 27260\n",
      "Ground truths non‑null : 22623\n",
      "Predictions made : 623\n",
      "Correct links : 161\n",
      "\n",
      "Accuracy : 0.5906%\n",
      "Precision @ linked : 25.8427%\n",
      "Recall : 0.7117%\n"
     ]
    }
   ],
   "source": [
    "def evaluate_linking(data):\n",
    "    total = 0        # every entity\n",
    "    linked = 0        # entities with a prediction\n",
    "    gts = 0        # entities that have a gold wiki_ID\n",
    "    correct = 0\n",
    "\n",
    "    for art in data:\n",
    "        for ent in art[\"entities\"]:\n",
    "            total += 1\n",
    "            gt = ent.get(\"entity wiki_ID\") or None\n",
    "            if gt:\n",
    "                gts += 1\n",
    "\n",
    "            pred_id = (ent.get(\"top_linked_entity\") or {}).get(\"cand_wiki_id\")\n",
    "            if pred_id:\n",
    "                linked += 1\n",
    "\n",
    "            if gt and pred_id and gt == pred_id:\n",
    "                correct += 1\n",
    "\n",
    "    accuracy  = correct / total if total else 0\n",
    "    precision = correct / linked if linked else 0\n",
    "    recall    = correct / gts if gts else 0\n",
    "\n",
    "    print(f\"Entities evaluated : {total}\")\n",
    "    print(f\"Ground truths non‑null : {gts}\")\n",
    "    print(f\"Predictions made : {linked}\")\n",
    "    print(f\"Correct links : {correct}\\n\")\n",
    "\n",
    "    print(f\"Accuracy : {accuracy:.4%}\")\n",
    "    print(f\"Precision @ linked : {precision:.4%}\")\n",
    "    print(f\"Recall : {recall:.4%}\")\n",
    "\n",
    "evaluate_linking(pointwise_sed_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d326424-d8c3-479c-b0ea-824539a92037",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "baseline-salient-entities",
   "language": "python",
   "name": "baseline"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
