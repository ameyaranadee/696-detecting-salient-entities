{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd2208e2-14e6-4801-8561-9f8c51554390",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tamaresh_umass_edu/.conda/envs/tej_baseline/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d85de17-629a-4081-858f-b8a68078d43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thefuzz import process\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37603c37-09c4-4392-805a-80a4a8ef84fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c87705e4-3a26-4fcf-9d3e-12ced39e6909",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4db731ad-7b95-417c-b76b-f0a639807f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/datasets/ai/llama3/hub/models--meta-llama--Llama-3.2-1B-Instruct/snapshots/9213176726f574b556790deb65791e0c5aa438b6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1361d5e8-2f49-448c-b592-35883133ec6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_paths = ['/datasets/ai/llama3/hub/models--meta-llama--Llama-3.2-1B-Instruct/snapshots/9213176726f574b556790deb65791e0c5aa438b6','datasets/ai/deepseek/hub/models--deepseek-ai--DeepSeek-R1-Distill-Qwen-1.5B/snapshots/530ca3e1ad39d440e182c2e4317aa40f012512fa','datasets/ai/t5/models--google--t5-v1_1-base/snapshots/b5fc947a416ea3cb079532cb3c2bbadeb7f800fc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3aef8b1-d5d7-4bb5-8f8c-5a2dd177c2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.float16).to(\"cuda\")  # Move model to CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e142af7f-be5d-4e9f-b72a-22d2361d8c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Cleans incomplete JSON response by:\n",
    "    1. Extracting the valid JSON part.\n",
    "    2. Removing incomplete entity objects.\n",
    "    3. Returning a properly formatted JSON dictionary.\n",
    "    4. Removes repeated entity titles in the dictionary.\n",
    "\"\"\"\n",
    "def clean_incomplete_json(response):\n",
    " \n",
    "    match = re.search(r'\\{.*\\}', response, re.DOTALL)\n",
    "    if not match:\n",
    "        raise ValueError(\"No valid JSON-like content found in the response.\")\n",
    "\n",
    "    json_like_str = match.group(0)\n",
    "\n",
    "\n",
    "    json_like_str = json_like_str.replace(\"'\", '\"')  # Ensure valid JSON quotes\n",
    "    json_like_str = re.sub(r',\\s*}', '}', json_like_str)  # Remove trailing commas before }\n",
    "    json_like_str = re.sub(r',\\s*\\]', ']', json_like_str)  # Remove trailing commas before ]\n",
    "\n",
    "   \n",
    "    entities_match = re.search(r'\"entities\":\\s*\\[(.*)', json_like_str, re.DOTALL)\n",
    "    if not entities_match:\n",
    "        raise ValueError(\"No 'entities' key found in the response.\")\n",
    "\n",
    "    entities_str = entities_match.group(1).strip()\n",
    "\n",
    "   \n",
    "    entity_blocks = re.findall(r'\\{[^{}]*\\}', entities_str, re.DOTALL)\n",
    "\n",
    "    valid_entities = []\n",
    "    for block in entity_blocks:\n",
    "        try:\n",
    "            entity = json.loads(block)  # Attempt to parse each block\n",
    "            valid_entities.append(entity)  # Keep valid entities\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Skipping invalid entity: {block}\")  # Debugging output\n",
    "\n",
    "   \n",
    "    cleaned_response = {\"entities\": valid_entities}\n",
    "     \n",
    "    cleaned_response[\"entities\"] = list({e[\"entity title\"]: e for e in cleaned_response[\"entities\"]}.values())\n",
    "\n",
    "    return cleaned_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9b5e2771-5225-488c-9086-8803d62f096b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def fuzzy_match(title, candidates, threshold=85):\n",
    "    best_match, score = process.extractOne(title, candidates)\n",
    "    return best_match if score >= threshold else None\n",
    "\n",
    "def evaluate_salience(ground_truth, model_output, threshold=85):\n",
    "    gt_dict = {}\n",
    "    for item in ground_truth:\n",
    "        title = item.get('entity title')\n",
    "        salience = item.get('entity salience')\n",
    "\n",
    "        if title:\n",
    "            title = title.lower()\n",
    "            try:\n",
    "                gt_dict[title] = int(salience) if salience is not None else 0\n",
    "            except ValueError:\n",
    "                gt_dict[title] = 0\n",
    "\n",
    "    pred_dict = {}\n",
    "    for item in model_output:\n",
    "        title = item.get('entity title')\n",
    "        salience = item.get('entity salience')\n",
    "\n",
    "        if title:\n",
    "            title = title.lower()\n",
    "            try:\n",
    "                pred_dict[title] = int(salience) if salience is not None else 0\n",
    "            except ValueError:\n",
    "                pred_dict[title] = 0\n",
    "        else:\n",
    "            print(\"Weird data : \",item)\n",
    "\n",
    "    # Apply fuzzy matching for better entity alignment\n",
    "    updated_pred_dict = {}\n",
    "    for pred_title in pred_dict:\n",
    "        matched_title = fuzzy_match(pred_title, list(gt_dict.keys()), threshold)\n",
    "        if matched_title:\n",
    "            updated_pred_dict[matched_title] = pred_dict[pred_title]\n",
    "        else:\n",
    "            updated_pred_dict[pred_title] = pred_dict[pred_title]\n",
    "\n",
    "    all_entities = set(gt_dict.keys()).union(set(updated_pred_dict.keys()))\n",
    "    y_true = [gt_dict.get(entity, 0) for entity in all_entities]\n",
    "    y_pred = [updated_pred_dict.get(entity, 0) for entity in all_entities]\n",
    "\n",
    "    return y_true, y_pred\n",
    "\n",
    "def evaluate_multiple_instances(ground_truths, model_outputs, threshold=85):\n",
    "    all_y_true = []\n",
    "    all_y_pred = []\n",
    "    \n",
    "    for gt, mo in zip(ground_truths, model_outputs):\n",
    "        y_true, y_pred = evaluate_salience(gt, mo, threshold)\n",
    "        all_y_true.extend(y_true)\n",
    "        all_y_pred.extend(y_pred)\n",
    "        \n",
    "    precision = precision_score(all_y_true, all_y_pred, average='macro')\n",
    "    recall = recall_score(all_y_true, all_y_pred, average='macro')\n",
    "    f1 = f1_score(all_y_true, all_y_pred, average='macro')\n",
    "    \n",
    "    # Compute accuracy based on fuzzy-matched salient entities\n",
    "    all_salient_correct = all(\n",
    "        gt_dict.get(entity, 0) == 1 and updated_pred_dict.get(entity, 0) == 1\n",
    "        for gt, mo in zip(ground_truths, model_outputs)\n",
    "        for gt_dict, updated_pred_dict in [\n",
    "            (\n",
    "                {fuzzy_match(item['entity title'].lower(), [x['entity title'].lower() for x in mo], threshold): int(item['entity salience']) for item in gt},\n",
    "                {item['entity title'].lower(): int(item['entity salience']) for item in mo}\n",
    "            )\n",
    "        ]\n",
    "        for entity in gt_dict if gt_dict[entity] == 1\n",
    "    )\n",
    "\n",
    "    accuracy = 1.0 if all_salient_correct else 0.0\n",
    "    \n",
    "    return {\"precision\": precision, \"recall\": recall, \"f1\": f1, \"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f4b0f8a-8c22-4464-ba80-c56afdc3d31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "######WORKS\n",
    "# def evaluate_salience(ground_truth, model_output):\n",
    "#     gt_dict = {}\n",
    "#     for item in ground_truth:\n",
    "#         title = item.get('entity title')\n",
    "#         salience = item.get('entity salience')\n",
    "\n",
    "#         if title is not None:  # Check if 'entity title' exists\n",
    "#             title = title.lower() # Lowercase only if title exists\n",
    "#             try:\n",
    "#                 salience = int(salience) if salience is not None else 0\n",
    "#                 gt_dict[title] = salience\n",
    "#             except ValueError:\n",
    "#                 print(f\"Warning: Could not convert salience to integer for title: {title}. Setting to 0.\")\n",
    "#                 gt_dict[title] = 0\n",
    "#         else:\n",
    "#             print(\"Warning: Found an item in ground_truth without an 'entity title'. Skipping.\", item)\n",
    "\n",
    "\n",
    "#     pred_dict = {}\n",
    "#     for item in model_output:\n",
    "#         title = item.get('entity title')\n",
    "#         salience = item.get('entity salience')\n",
    "\n",
    "#         if title is not None:\n",
    "#             title = title.lower()\n",
    "#             try:\n",
    "#                 salience = int(salience) if salience is not None else 0\n",
    "#                 pred_dict[title] = salience\n",
    "#             except ValueError:\n",
    "#                 print(f\"Warning: Could not convert salience to integer for title: {title}. Setting to 0.\")\n",
    "#                 pred_dict[title] = 0\n",
    "#         else:\n",
    "#             print(\"Warning: Found an item in model_output without an 'entity title'. Skipping.\")\n",
    "\n",
    "#     all_entities = set(gt_dict.keys()).union(set(pred_dict.keys()))\n",
    "#     y_true = [gt_dict.get(entity, 0) for entity in all_entities]\n",
    "#     y_pred = [pred_dict.get(entity, 0) for entity in all_entities]\n",
    "\n",
    "#     return y_true, y_pred\n",
    "\n",
    "# def evaluate_multiple_instances(ground_truths, model_outputs):\n",
    "#     all_y_true = []\n",
    "#     all_y_pred = []\n",
    "    \n",
    "#     for gt, mo in zip(ground_truths, model_outputs):\n",
    "#         y_true, y_pred = evaluate_salience(gt, mo)\n",
    "#         all_y_true.extend(y_true)\n",
    "#         all_y_pred.extend(y_pred)\n",
    "        \n",
    "#     precision = precision_score(all_y_true, all_y_pred, average='macro')  # or 'micro', 'weighted'\n",
    "#     recall = recall_score(all_y_true, all_y_pred, average='macro')      # or 'micro', 'weighted'\n",
    "#     f1 = f1_score(all_y_true, all_y_pred, average='macro')          \n",
    "    \n",
    "#     # precision = precision_score(all_y_true, all_y_pred)\n",
    "#     # recall = recall_score(all_y_true, all_y_pred)\n",
    "#     # f1 = f1_score(all_y_true, all_y_pred)\n",
    "    \n",
    "#     all_salient_correct = all(\n",
    "#         gt_dict.get(entity, 0) == 1 and pred_dict.get(entity, 0) == 1 \n",
    "#         for gt, mo in zip(ground_truths, model_outputs)\n",
    "#         for gt_dict, pred_dict in [(dict((item['entity title'].lower(), int(item['entity salience'])) for item in gt),\n",
    "#                                     dict((item['entity title'].lower(), int(item['entity salience'])) for item in mo))]\n",
    "#         for entity in gt_dict if gt_dict[entity] == 1\n",
    "#     )\n",
    "   \n",
    "#     accuracy = 1.0 if all_salient_correct else 0.0\n",
    "    \n",
    "#     return {\"precision\": precision, \"recall\": recall, \"f1\": f1, \"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab47dbe2-47be-49d1-8dd1-2c8dc2a5efb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_path = \"work/pi_wenlongzhao_umass_edu/8/tej/696-detecting-salient-entities/data/article_info.json\"\n",
    "file_path = \"./data/article_info.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf6aedf5-47e5-4a95-ab16-8147c90773a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36b6abe2-28b3-4f55-bb8c-01cadd8619a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity title': 'United States', 'entity salience': '1'},\n",
       " {'entity title': 'Washington, D.C.', 'entity salience': '1'},\n",
       " {'entity title': 'same-sex marriage', 'entity salience': '0'},\n",
       " {'entity title': 'Adrian Fenty', 'entity salience': '0'},\n",
       " {'entity title': 'federal district', 'entity salience': '0'},\n",
       " {'entity title': 'family values', 'entity salience': '0'},\n",
       " {'entity title': 'John Roberts', 'entity salience': '0'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['entities'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f4cf0b0-87a2-4071-8f1d-d965864a62f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aeec6a82-92a7-4826-bf7e-d99067b4c975",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3\n",
      "Iteration 4\n",
      "METRICS {'precision': 0.4617554858934169, 'recall': 0.4175675675675675, 'f1': 0.4156231365533691, 'accuracy': 0.0}\n",
      "\n",
      "\n",
      "[[{'entity title': 'Washington, D.C.', 'entity salience': '1'}, {'entity title': 'United States capital of Washington, D.C.', 'entity salience': '1'}, {'entity title': 'Same-sex marriage', 'entity salience': '1'}, {'entity title': 'Washington D.C.', 'entity salience': '1'}, {'entity title': 'Mayor Adrian Fenty', 'entity salience': '1'}, {'entity title': 'Congress', 'entity salience': '1'}, {'entity title': 'Supreme Court Chief Justice John Roberts', 'entity salience': '1'}, {'entity title': 'December', 'entity salience': '0'}, {'entity title': 'United States', 'entity salience': '0'}, {'entity title': 'Supreme Court', 'entity salience': '0'}, {'entity title': 'John Roberts', 'entity salience': '0'}, {'entity title': 'Washington', 'entity salience': '0'}, {'entity title': 'D.C.', 'entity salience': '0'}, {'entity title': 'John F. Kennedy', 'entity salience': '0'}, {'entity title': 'Adrian Fenty', 'entity salience': '1'}], [{'entity title': 'New York Representative Eric Massa', 'entity salience': 1}, {'entity title': 'United States Congresspeople', 'entity salience': 0}, {'entity title': 'Congressman', 'entity salience': 0}, {'entity title': 'New York', 'entity salience': 1}, {'entity title': '29th congressional district', 'entity salience': 0}, {'entity title': 'December 2009', 'entity salience': 0}, {'entity title': 'United States', 'entity salience': 1}, {'entity title': 'Congress', 'entity salience': 0}, {'entity title': 'Eric Massa', 'entity salience': 1}, {'entity title': 'Cancer', 'entity salience': 1}, {'entity title': 'Non-specific cancer recurrence', 'entity salience': 0}, {'entity title': 'Terminal', 'entity salience': 1}, {'entity title': 'Final phase', 'entity salience': 0}, {'entity title': 'Controlled pace', 'entity salience': 1}, {'entity title': 'Sexual harassment', 'entity salience': 0}, {'entity title': 'Aide', 'entity salience': 0}], [{'entity title': 'Air Canada', 'entity salience': '1'}, {'entity title': 'Aveos Fleet Performance', 'entity salience': '1'}, {'entity title': 'Aircraft', 'entity salience': '1'}, {'entity title': 'Airbus', 'entity salience': '1'}, {'entity title': 'A319', 'entity salience': '1'}, {'entity title': 'A320', 'entity salience': '1'}, {'entity title': 'Montréal', 'entity salience': '1'}, {'entity title': 'Winnipeg', 'entity salience': '1'}, {'entity title': 'Vancouver', 'entity salience': '1'}, {'entity title': 'Aveos', 'entity salience': '1'}, {'entity title': 'Fleet', 'entity salience': '1'}, {'entity title': 'Performance', 'entity salience': '1'}, {'entity title': 'Maintenance', 'entity salience': '1'}, {'entity title': 'Company', 'entity salience': '1'}, {'entity title': 'Layoffs', 'entity salience': '1'}, {'entity title': 'Permanent', 'entity salience': '1'}, {'entity title': 'Temporary', 'entity salience': '1'}], [{'entity title': 'Former Bosnian president', 'entity salience': '1'}, {'entity title': 'Metropolitan Police', 'entity salience': '0'}, {'entity title': 'Dr. Ejup Ganić', 'entity salience': '1'}, {'entity title': 'Serbian government', 'entity salience': '1'}, {'entity title': 'Bosnia', 'entity salience': '1'}, {'entity title': 'Bosnian Serbs', 'entity salience': '1'}, {'entity title': 'Bosniak', 'entity salience': '0'}, {'entity title': 'Bosnia and Herzegovina', 'entity salience': '1'}, {'entity title': 'Buckingham University', 'entity salience': '0'}, {'entity title': 'Sarajevo', 'entity salience': '1'}, {'entity title': 'Sarajevans', 'entity salience': '1'}, {'entity title': 'Bosnian Muslim', 'entity salience': '0'}, {'entity title': 'The Hague', 'entity salience': '1'}, {'entity title': 'Benjamin Franklin Institute of Technology', 'entity salience': '0'}, {'entity title': 'Boston', 'entity salience': '0'}, {'entity title': 'American universities', 'entity salience': '0'}, {'entity title': 'Association of Detainees of Republika Srpska', 'entity salience': '1'}, {'entity title': 'Haris Silajdžić', 'entity salience': '0'}, {'entity title': 'Damir Arnaut', 'entity salience': '0'}, {'entity title': 'Dr. Snezana Malovic', 'entity salience': '1'}], [{'entity title': 'Euro', 'entity salience': '1'}, {'entity title': 'US dollar', 'entity salience': '0'}, {'entity title': 'Greece', 'entity salience': '0'}, {'entity title': 'pound', 'entity salience': '0'}, {'entity title': 'British', 'entity salience': '0'}, {'entity title': 'CMC Markets', 'entity salience': '0'}, {'entity title': 'Agence France-Presse', 'entity salience': '0'}, {'entity title': 'Michael Hewson', 'entity salience': '0'}, {'entity title': 'Greek bailout', 'entity salience': '0'}, {'entity title': 'Greek debt crisis', 'entity salience': '0'}, {'entity title': 'Europe', 'entity salience': '0'}, {'entity title': 'pence', 'entity salience': '0'}, {'entity title': 'May', 'entity salience': '0'}, {'entity title': 'last year', 'entity salience': '0'}, {'entity title': 'May of last year', 'entity salience': '0'}, {'entity title': 'British pound', 'entity salience': '0'}]]\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "articles = list(df['text'])\n",
    "titles = list(df['title'])\n",
    "prompt_template = '''\n",
    "Article Title: {title}\n",
    "Article Text: {article}\n",
    "\n",
    "You are an expert news article analysis assistant. Given an article's title and its text, your task is to extract the entities \n",
    "mentioned in the article and assign a salience score to each entity. The salience score is defined as follows:\n",
    "• 1: The entity is central to the article's content.\n",
    "• 0: The entity is mentioned but is not central.\n",
    "\n",
    "Follow these rules:\n",
    "1. Only extract entities that are explicitly mentioned in the article.\n",
    "2. Do not include any entities that do not appear in the article.\n",
    "3. Use only the provided title and text to determine salience.\n",
    "4. Format your answer as valid JSON exactly as specified below.\n",
    "5. Do not infinitely loop on the same words for any of the entity titles.\n",
    "6. Every entity title should appear only once.\n",
    "\n",
    "The expected JSON format is:\n",
    "{{\n",
    "  \"entities\": [\n",
    "    {{\n",
    "      \"entity title\": \"<entity_name>\",\n",
    "      \"entity salience\": \"<0 or 1>\"\n",
    "    }},\n",
    "    ...\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Now, based on the article above, return only the final JSON output (with no extra commentary).\n",
    "'''\n",
    "\n",
    "\n",
    "####RUNS ZERO SHOT FOR EVERY MODEL SPECIFIED IN MODEL PATHS###########\n",
    "i = 0\n",
    "n = 5 #num instances\n",
    "for model_path in model_paths[:1]:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.float16).to(\"cuda\")  # Move model to CUDA\n",
    "    for title,article in zip(titles[:n],articles[:n]):\n",
    "        prompt = prompt_template.format(title=title, article=article)\n",
    "        input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "        \n",
    "        # Generate response\n",
    "        output_ids = model.generate(input_ids, max_new_tokens=1000)\n",
    "\n",
    "        # Decode and print the response\n",
    "        response = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "        \n",
    "        response = response.split(\"Now, based on the article above, return only the final JSON output (with no extra commentary).\")[-1]\n",
    "        result = clean_incomplete_json(response)\n",
    "        print(\"Iteration\", i)\n",
    "        i+=1\n",
    "        outputs.append(result['entities'])\n",
    "\n",
    "f = open('outputs.txt','w+')\n",
    "f.write(str(outputs))\n",
    "f.close()\n",
    "\n",
    "metrics = evaluate_multiple_instances(df['entities'][:n],outputs)\n",
    "print(\"METRICS\",metrics)\n",
    "print(\"\\n\")\n",
    "print(outputs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fced658b-1935-4d55-9eb3-9cff4a634625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity title': 'United States capital of Washington, D.C.',\n",
       "  'entity salience': '1'},\n",
       " {'entity title': 'Washington, D.C.', 'entity salience': '1'},\n",
       " {'entity title': 'United States territory', 'entity salience': '1'},\n",
       " {'entity title': 'Same-sex marriage', 'entity salience': '1'},\n",
       " {'entity title': 'Washington D.C.', 'entity salience': '1'},\n",
       " {'entity title': 'Mayor Adrian Fenty', 'entity salience': '1'},\n",
       " {'entity title': 'Supreme Court Chief Justice John Roberts',\n",
       "  'entity salience': '1'},\n",
       " {'entity title': 'Congress', 'entity salience': '0'},\n",
       " {'entity title': 'December', 'entity salience': '0'}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "60f8faf6-520f-4ba4-9555-6d15e2d8c941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.6140350877192983,\n",
       " 'recall': 0.5886363636363636,\n",
       " 'f1': 0.5982142857142857,\n",
       " 'accuracy': 0.0}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db450035-2db5-40fb-9cb0-c8b2702c7687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'entity title': 'Canadian', 'entity salience': '1'},\n",
       "  {'entity title': 'Air Canada', 'entity salience': '0'},\n",
       "  {'entity title': 'Aveos Fleet Performance', 'entity salience': '0'},\n",
       "  {'entity title': 'Montreal', 'entity salience': '0'},\n",
       "  {'entity title': 'Winnipeg', 'entity salience': '0'},\n",
       "  {'entity title': 'Vancouver', 'entity salience': '0'},\n",
       "  {'entity title': 'Airbus A319 and A320', 'entity salience': '0'}],\n",
       " [{'entity title': 'United States capital of Washington, D.C.',\n",
       "   'entity salience': '1'},\n",
       "  {'entity title': 'Washington, D.C.', 'entity salience': '1'},\n",
       "  {'entity title': 'United States territory', 'entity salience': '1'},\n",
       "  {'entity title': 'Same-sex marriage', 'entity salience': '1'},\n",
       "  {'entity title': 'Washington D.C.', 'entity salience': '1'},\n",
       "  {'entity title': 'Mayor Adrian Fenty', 'entity salience': '1'},\n",
       "  {'entity title': 'Supreme Court Chief Justice John Roberts',\n",
       "   'entity salience': '1'},\n",
       "  {'entity title': 'Congress', 'entity salience': '0'},\n",
       "  {'entity title': 'December', 'entity salience': '0'}])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['entities'][2], outputs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855b607a-971f-4c98-a2e9-f04f1568633e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######TEST FOR ONE ARTICLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb892195-d920-40c1-bba1-df8835e6f9a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a65abf91-4562-43f8-9a41-10b6e3c76013",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Incorrect path_or_model_id: 'datasets/ai/deepseek/hub/models--deepseek-ai--DeepSeek-R1-Distill-Qwen-1.5B/snapshots/530ca3e1ad39d440e182c2e4317aa40f012512fa'. Please provide either the path to a local folder or the repo_id of a model on the Hub.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/tej_baseline/lib/python3.9/site-packages/transformers/utils/hub.py:342\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 342\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.conda/envs/tej_baseline/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py:106\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 106\u001b[0m     \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/tej_baseline/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py:154\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m repo_id\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must be in the form \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrepo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnamespace/repo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Use `repo_type` argument if needed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m     )\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n",
      "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': 'datasets/ai/deepseek/hub/models--deepseek-ai--DeepSeek-R1-Distill-Qwen-1.5B/snapshots/530ca3e1ad39d440e182c2e4317aa40f012512fa'. Use `repo_type` argument if needed.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m####PROMPT 1##\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_paths\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_paths[\u001b[38;5;241m1\u001b[39m], torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Move model to CUDA\u001b[39;00m\n\u001b[1;32m      4\u001b[0m context_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'''\u001b[39m\u001b[38;5;124mThe United States capital of Washington, D.C. legalized same-sex marriage on Wednesday. Beginning at 6 A.M. local time (1100 UTC), couples began submitting marriage applications at local courthouses citywide.Washington D.C. becomes the seventh United States territory to legalize same sex marriage. The bill was ratified by Mayor Adrian Fenty last December. Due to city\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms territorial status as a federal district, the bill had to be reviewed by congress. The bill passed congressional review Tuesday night.The bill faced opposition from many family values activists, who tried to stop the bill from becoming law. Supreme Court Chief Justice John Roberts rejected a lawsuit to prevent the measure.\u001b[39m\u001b[38;5;124m'''\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/tej_baseline/lib/python3.9/site-packages/transformers/models/auto/tokenization_auto.py:881\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    880\u001b[0m \u001b[38;5;66;03m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[39;00m\n\u001b[0;32m--> 881\u001b[0m tokenizer_config \u001b[38;5;241m=\u001b[39m \u001b[43mget_tokenizer_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tokenizer_config:\n\u001b[1;32m    883\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m tokenizer_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/tej_baseline/lib/python3.9/site-packages/transformers/models/auto/tokenization_auto.py:713\u001b[0m, in \u001b[0;36mget_tokenizer_config\u001b[0;34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, **kwargs)\u001b[0m\n\u001b[1;32m    710\u001b[0m     token \u001b[38;5;241m=\u001b[39m use_auth_token\n\u001b[1;32m    712\u001b[0m commit_hash \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 713\u001b[0m resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43mTOKENIZER_CONFIG_FILE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_gated_repo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    730\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not locate the tokenizer configuration file, will try to use the model config instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/tej_baseline/lib/python3.9/site-packages/transformers/utils/hub.py:408\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere was a specific connection error when trying to load \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HFValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect path_or_model_id: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Please provide either the path to a local folder or the repo_id of a model on the Hub.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    410\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resolved_file\n",
      "\u001b[0;31mOSError\u001b[0m: Incorrect path_or_model_id: 'datasets/ai/deepseek/hub/models--deepseek-ai--DeepSeek-R1-Distill-Qwen-1.5B/snapshots/530ca3e1ad39d440e182c2e4317aa40f012512fa'. Please provide either the path to a local folder or the repo_id of a model on the Hub."
     ]
    }
   ],
   "source": [
    "####PROMPT 1##\n",
    "\n",
    "context_str = '''The United States capital of Washington, D.C. legalized same-sex marriage on Wednesday. Beginning at 6 A.M. local time (1100 UTC), couples began submitting marriage applications at local courthouses citywide.Washington D.C. becomes the seventh United States territory to legalize same sex marriage. The bill was ratified by Mayor Adrian Fenty last December. Due to city's territorial status as a federal district, the bill had to be reviewed by congress. The bill passed congressional review Tuesday night.The bill faced opposition from many family values activists, who tried to stop the bill from becoming law. Supreme Court Chief Justice John Roberts rejected a lawsuit to prevent the measure.'''\n",
    "prompt = '''\n",
    "You are an editor for a newspaper who has to identify the most critical pieces of\n",
    ",→ information when writing the headline for an article.\n",
    "For this task you are given a question-answer pair as Context and a list of\n",
    "entities from the text. Read the Context given in triple backticks and rate\n",
    "how salient each entity is to the Context. Before answering provide a short\n",
    "justification for your answer.\n",
    ",→\n",
    ",→\n",
    ",→\n",
    "Provide a salience score of 0 or 1 where 0 is non-salient and 1 is\n",
    ",→ salient.\n",
    "Provide a categorical rating from the following options:\n",
    "High - The entity is strongly related to the main point of the question-answer\n",
    ",→ pair or is the answer itself.\n",
    "Moderate - The entity is related to the question-answer pair but it is not the\n",
    ",→ most important part.\n",
    "Low - The entity not related or is only tangentially or superficially related\n",
    ",→ to the question-answer pair.\n",
    "Countries (especially in reference to nationality) are frequently incidental to the\n",
    "answer and are most often “Low” salience unless directly related to the\n",
    "question.\n",
    ",→\n",
    ",→\n",
    "Give your answer as valid JSON in the following format:\n",
    "[\n",
    "{{\n",
    "\"entity\": <entity_name>,\n",
    "\"explanation\": <explanation of the rating>,\n",
    "\"rating\": <rating>,\n",
    "\"score\": <score>,\n",
    "}}\n",
    "]\n",
    "Context: ```{context_str}```\n",
    "List of entities: {entity_str}\n",
    "Answer:\n",
    "'''\n",
    "\n",
    "# Tokenize the prompt and move input to CUDA\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "\n",
    "# Generate response\n",
    "output_ids = model.generate(input_ids, max_length=500)\n",
    "\n",
    "# Decode and print the response\n",
    "response = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f180bb3a-13e3-4e64-a1e2-f9d769c93753",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESPONSE {'entities': [{'entity title': 'United States capital of Washington, D.C.', 'entity salience': '1'}, {'entity title': 'Washington, D.C.', 'entity salience': '1'}, {'entity title': 'United States territory', 'entity salience': '1'}, {'entity title': 'Same-sex marriage', 'entity salience': '1'}, {'entity title': 'Washington D.C.', 'entity salience': '1'}, {'entity title': 'Mayor Adrian Fenty', 'entity salience': '1'}, {'entity title': 'Supreme Court Chief Justice John Roberts', 'entity salience': '1'}, {'entity title': 'Congress', 'entity salience': '0'}, {'entity title': 'December', 'entity salience': '0'}]}\n"
     ]
    }
   ],
   "source": [
    "#####PROMPT2#####\n",
    "\n",
    "article = '''The United States capital of Washington, D.C. legalized same-sex marriage on Wednesday. Beginning at 6 A.M. local time (1100 UTC), couples began submitting marriage applications at local courthouses citywide.Washington D.C. becomes the seventh United States territory to legalize same sex marriage. The bill was ratified by Mayor Adrian Fenty last December. Due to city's territorial status as a federal district, the bill had to be reviewed by congress. The bill passed congressional review Tuesday night.The bill faced opposition from many family values activists, who tried to stop the bill from becoming law. Supreme Court Chief Justice John Roberts rejected a lawsuit to prevent the measure.'''\n",
    "title = '''Laws allowing same sex marriage in Washington, D.C. go into effect'''\n",
    "prompt = f'''\n",
    "Article Title: {title}\n",
    "Article Text: {article}\n",
    "\n",
    "You are an expert news article analysis assistant. Given an article's title and its text, your task is to extract the entities \n",
    "mentioned in the article and assign a salience score to each entity. The salience score is defined as follows:\n",
    "•⁠  ⁠1: The entity is central to the article's content.\n",
    "•⁠  ⁠0: The entity is mentioned but is not central.\n",
    "\n",
    "Follow these rules:\n",
    "1.⁠ ⁠Only extract entities that are explicitly mentioned in the article.\n",
    "2.⁠ ⁠Do not include any entities that do not appear in the article.\n",
    "3.⁠ ⁠Use only the provided title and text to determine salience.\n",
    "4.⁠ ⁠Format your answer as valid JSON exactly as specified below.\n",
    "5. Do not infinitely loop on the same words for any of the entity titles\n",
    "6. Every entity title should appear only once\n",
    "\n",
    "The expected JSON format is:\n",
    "{{\n",
    "  \"entities\": [\n",
    "    {{\n",
    "      \"entity title\": \"<entity_name>\",\n",
    "      \"entity salience\": \"<0 or 1>\"\n",
    "    }},\n",
    "    ...\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Now, based on the article above, return only the final JSON output (with no extra commentary).\n",
    "'''\n",
    "# Tokenize the prompt and move input to CUDA\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "\n",
    "# Generate response\n",
    "output_ids = model.generate(input_ids, max_length=1000)\n",
    "\n",
    "# Decode and print the response\n",
    "response = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "response = response.split(\"Now, based on the article above, return only the final JSON output (with no extra commentary).\")[-1]\n",
    "result = clean_incomplete_json(response)\n",
    "print(\"RESPONSE\",result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77f5e944-7511-4359-99dc-c19f13996f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entities': [{'entity title': 'United States capital of Washington, D.C.',\n",
       "   'entity salience': '1'},\n",
       "  {'entity title': 'Washington, D.C.', 'entity salience': '1'},\n",
       "  {'entity title': 'United States territory', 'entity salience': '1'},\n",
       "  {'entity title': 'Same-sex marriage', 'entity salience': '1'},\n",
       "  {'entity title': 'Washington D.C.', 'entity salience': '1'},\n",
       "  {'entity title': 'Mayor Adrian Fenty', 'entity salience': '1'},\n",
       "  {'entity title': 'Supreme Court Chief Justice John Roberts',\n",
       "   'entity salience': '1'},\n",
       "  {'entity title': 'Congress', 'entity salience': '0'},\n",
       "  {'entity title': 'December', 'entity salience': '0'}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8d178a1-025c-446c-adcc-4376191bec81",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dictionary update sequence element #0 has length 1; 2 is required",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'''\u001b[39;49m\u001b[38;5;124;43m{\u001b[39;49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;43m  \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mentities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m: [\u001b[39;49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;43m    \u001b[39;49m\u001b[38;5;124;43m'''\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: dictionary update sequence element #0 has length 1; 2 is required"
     ]
    }
   ],
   "source": [
    "dict(response.split('''{\n",
    "  \"entities\": [\n",
    "    ''')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6a86086-cf9d-44fb-a381-998839ab6d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"entities\": [\n",
      "    {\n",
      "      \"entity title\": \"Washington, D.C.\",\n",
      "      \"entity salience\": \"1\"\n",
      "    },\n",
      "    {\n",
      "      \"entity title\": \"United States capital\",\n",
      "      \"entity salience\": \"1\"\n",
      "    },\n",
      "    {\n",
      "      \"entity title\": \"Same-sex marriage\",\n",
      "      \"entity salience\": \"1\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def clean_incomplete_json(response: str):\n",
    "    \"\"\"\n",
    "    Cleans an incomplete JSON response by:\n",
    "    1. Extracting the valid JSON part.\n",
    "    2. Removing incomplete entity objects.\n",
    "    3. Returning a properly formatted JSON dictionary.\n",
    "    \"\"\"\n",
    "    # Extract the JSON-like substring\n",
    "    match = re.search(r'\\{.*\\}', response, re.DOTALL)\n",
    "    if not match:\n",
    "        raise ValueError(\"No valid JSON-like content found in the response.\")\n",
    "\n",
    "    json_like_str = match.group(0)\n",
    "\n",
    "    # Fix common JSON formatting issues\n",
    "    json_like_str = json_like_str.replace(\"'\", '\"')  # Ensure valid JSON quotes\n",
    "    json_like_str = re.sub(r',\\s*}', '}', json_like_str)  # Remove trailing commas before }\n",
    "    json_like_str = re.sub(r',\\s*\\]', ']', json_like_str)  # Remove trailing commas before ]\n",
    "\n",
    "    # Find the entities list\n",
    "    entities_match = re.search(r'\"entities\":\\s*\\[(.*)', json_like_str, re.DOTALL)\n",
    "    if not entities_match:\n",
    "        raise ValueError(\"No 'entities' key found in the response.\")\n",
    "\n",
    "    entities_str = entities_match.group(1).strip()\n",
    "\n",
    "    # Extract individual entity blocks using regex\n",
    "    entity_blocks = re.findall(r'\\{[^{}]*\\}', entities_str, re.DOTALL)\n",
    "\n",
    "    valid_entities = []\n",
    "    for block in entity_blocks:\n",
    "        try:\n",
    "            entity = json.loads(block)  # Attempt to parse each block\n",
    "            valid_entities.append(entity)  # Keep valid entities\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Skipping invalid entity: {block}\")  # Debugging output\n",
    "\n",
    "    # Construct valid JSON response\n",
    "    cleaned_response = {\"entities\": valid_entities}\n",
    "\n",
    "    return cleaned_response\n",
    "\n",
    "# Example incomplete response\n",
    "response = '''{\n",
    "  \"entities\": [\n",
    "    {\n",
    "      \"entity title\": \"Washington, D.C.\",\n",
    "      \"entity salience\": \"1\"\n",
    "    },\n",
    "    {\n",
    "      \"entity title\": \"United States capital\",\n",
    "      \"entity salience\": \"1\"\n",
    "    },\n",
    "    {\n",
    "      \"entity title\": \"Same-sex marriage\",\n",
    "      \"entity salience\": \"1\"\n",
    "      },'''  # Incomplete object\n",
    "\n",
    "try:\n",
    "    parsed_response = clean_incomplete_json(response)\n",
    "    print(json.dumps(parsed_response, indent=2))\n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a1e5595-d5ed-4233-962a-bd6719e127b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = {\n",
    "  \"entities\": [\n",
    "    {\n",
    "      \"entity title\": \"Washington, D.C.\",\n",
    "      \"entity salience\": \"1\"\n",
    "    },\n",
    "    {\n",
    "      \"entity title\": \"United States capital\",\n",
    "      \"entity salience\": \"1\"\n",
    "    },\n",
    "    {\n",
    "      \"entity title\": \"Same-sex marriage\",\n",
    "      \"entity salience\": \"1\"\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee10953d-d65c-40dc-a481-31296b4da007",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = [{'entity title': 'United States', 'entity salience': '1'},\n",
    " {'entity title': 'Washington, D.C.', 'entity salience': '1'},\n",
    " {'entity title': 'same-sex marriage', 'entity salience': '0'},\n",
    " {'entity title': 'Adrian Fenty', 'entity salience': '0'},\n",
    " {'entity title': 'federal district', 'entity salience': '0'},\n",
    " {'entity title': 'family values', 'entity salience': '0'},\n",
    " {'entity title': 'John Roberts', 'entity salience': '0'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b21b65fc-7e61-42ed-a767-cde31299bb7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mevaluate_salience\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgt\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mentities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m, in \u001b[0;36mevaluate_salience\u001b[0;34m(ground_truth, model_output)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mevaluate_salience\u001b[39m(ground_truth, model_output):\n\u001b[1;32m      2\u001b[0m     gt_dict \u001b[38;5;241m=\u001b[39m {item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentity title\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mlower(): \u001b[38;5;28mint\u001b[39m(item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentity salience\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m ground_truth}\n\u001b[0;32m----> 3\u001b[0m     pred_dict \u001b[38;5;241m=\u001b[39m {item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentity title\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mlower(): \u001b[38;5;28mint\u001b[39m(item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentity salience\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodel_output\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mentities\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m}\n\u001b[1;32m      5\u001b[0m     all_entities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(gt_dict\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;241m.\u001b[39munion(\u001b[38;5;28mset\u001b[39m(pred_dict\u001b[38;5;241m.\u001b[39mkeys()))\n\u001b[1;32m      6\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m [gt_dict\u001b[38;5;241m.\u001b[39mget(entity, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m entity \u001b[38;5;129;01min\u001b[39;00m all_entities]\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "evaluate_salience(gt,mod[\"entities\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307e087a-d012-480f-9c84-4ba014b1da4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tej_baseline",
   "language": "python",
   "name": "tej_baseline"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
