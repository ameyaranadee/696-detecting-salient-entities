{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd2208e2-14e6-4801-8561-9f8c51554390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab47dbe2-47be-49d1-8dd1-2c8dc2a5efb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_path = \"work/pi_wenlongzhao_umass_edu/8/tej/696-detecting-salient-entities/data/article_info.json\"\n",
    "# file_path = \"./data/article_info.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6aedf5-47e5-4a95-ab16-8147c90773a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(file_path, \"r\") as f:\n",
    "#     data = json.load(f)\n",
    "# df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1455e49e-3861-49e0-b878-7c0db0d2530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_paths = ['/datasets/ai/llama3/meta-llama/models--meta-llama--Llama-3.2-1B-Instruct/snapshots/9213176726f574b556790deb65791e0c5aa438b6','datasets/ai/deepseek/hub/models--deepseek-ai--DeepSeek-R1-Distill-Qwen-1.5B/snapshots/530ca3e1ad39d440e182c2e4317aa40f012512fa','datasets/ai/t5/models--google--t5-v1_1-base/snapshots/b5fc947a416ea3cb079532cb3c2bbadeb7f800fc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68df3c91-1b9d-42bf-921c-006ed1ada329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = '/datasets/ai/llama3/hub/models--meta-llama--Llama-3.2-1B-Instruct/snapshots/9213176726f574b556790deb65791e0c5aa438b6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0885cd9a-5b11-4cfe-9beb-e027c8f8f94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.float16).to(\"cuda\")  # Move model to CUDA\n",
    "\n",
    "# # Tokenize the prompt and move input to CUDA\n",
    "# input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "\n",
    "# # Generate response\n",
    "# output_ids = model.generate(input_ids, max_length=1000)\n",
    "\n",
    "# # Decode and print the response\n",
    "# response = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f0bf7a-cd46-4f42-9ade-ce902b48364e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantization_config = BitsAndBytesConfig(\n",
    "#         load_in_4bit=True,\n",
    "#         bnb_4bit_quant_type=\"nf4\",\n",
    "#         bnb_4bit_compute_dtype=\"torch.float16\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2c86b12-7a34-4c75-92c6-fcf9cdae3443",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/datasets/ai/llama3/hub/models--meta-llama--Meta-Llama-3.1-8B-Instruct/snapshots/5206a32e0bd3067aef1ce90f5528ade7d866253f\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40490ce8-5c61-41d3-9057-c1902fe30c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-05 00:54:06.810773: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741136046.826714 3892571 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741136046.831372 3892571 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-05 00:54:06.849326: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/aranade_umass_edu/.conda/envs/intro/lib/python3.9/site-packages/accelerate/utils/modeling.py:1536: UserWarning: Current model requires 128 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc79132b99a9436f94c88f0a88601c8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.float16, device_map='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de490203-16fd-46d2-a0ad-01b7ca5e93de",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'FAA: Jets at New York airport directed by child'\n",
    "\n",
    "article = '''A US air traffic controller and his supervisor have been placed on administrative leave and are under investigation after a small boy was apparently allowed\n",
    "to direct passenger airplanes at New York's John F. Kennedy International Airport.A probe was started after tape recordings indicated that a small child, which The \n",
    "Telegraph describes as sounding seven or eight years old, was heard directing air traffic from the airport on February 16.JetBlue 171 contact departure, was one of the \n",
    "child's directions. The pilot of the addressed aircraft responded by saying: Over to departure JetBlue 171, awesome job. In another direction, the child says MS 4-0-3, \n",
    "contact departure [...] Adios, amigo. The pilot replied with Adios, amigo.A man is later heard saying [h]ere's what you get, guys, when the kids are out of school. The \n",
    "age of the child and the name of their father wasn't immediately available.An aviation official who asked to remain anonymous later told media that the same controller \n",
    "took his daughter into the control tower the next day, and that she was allowed to communicate with two pilots. According to another official, the two children are \n",
    "twins.The Federal Aviation Administration (FAA), meanwhile, announced that all unofficial visits to towers, radar rooms, and other air traffic control areas, would be \n",
    "prohibited while the investigation is being conducted. Pending the outcome of our investigation, the employees involved in this incident are not controlling air traffic,\n",
    "the aviation authority said in a statement.Administrator Randy Babbitt commented about the incident. This lapse in judgment not only violated FAA's own policies but \n",
    "common sense standards for professional conduct. These kinds of distractions are totally unacceptable. We have an incredible team of professionals who safely control \n",
    "our nation's skies every single day. This kind of behavior does not reflect the true caliber of our work force.The National Air Traffic Controllers Association, which \n",
    "is the union representing controllers, also stated that [w]e do not condone this type of behaviour in any way. It is not indicative of the highest professional standards\n",
    "that controllers set for themselves and exceed each and every day in the advancement of aviation safety.However, Dave Pascoe, the owner of LiveATC.net, a website which\n",
    "keeps records of air traffic communications, including those involving the aforementioned child, described the incident as being blown out of proportion, saying to CNN \n",
    "that [...] when you listen to any of the recordings, the situation in the tower is very controlled. There is no hint [...] that anyone was too busy or anyone was \n",
    "interrupting the planes. [...] It was very controlled, and I don't think safety was compromised, nor should anyone be disciplined for this.[...] I have every belief that \n",
    "they'd make sure there were additional eyes there. JFK is highly supervised. It's not just one controller controlling the runway. Supervisors are there, and multiple \n",
    "people are there making sure by looking through binoculars and at radar. Pascoe is also a pilot.\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6546c86-482e-47ca-bbd3-f13779b7fe8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Zero-shot prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a65abf91-4562-43f8-9a41-10b6e3c76013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = f'''\n",
    "# Article Title: {title}\n",
    "# Article Text: {article}\n",
    "\n",
    "# You are an expert news article analysis assistant. The salience of an entity provides information about the importance or the centrality of that entity to the \n",
    "# article text. Given an article's title and its text, your task is to extract the entities mentioned in the article and assign a salience score to each entity. \n",
    "# The salience score is defined as follows:\n",
    "# - 1: The entity is salient as per the article's context.\n",
    "# - 0: The entity is mentioned but is not salient.\n",
    "\n",
    "# Follow these rules:\n",
    "# 1. Only extract entities that are explicitly mentioned in the article.\n",
    "# 2. Do not include any entities that do not appear in the article.\n",
    "# 3. Use only the provided title and text to determine salience.\n",
    "# 4. Format your answer as valid JSON exactly as specified below.\n",
    "\n",
    "# The expected JSON format is:\n",
    "# {{\n",
    "#   \"entities\": [\n",
    "#     {{\n",
    "#       \"entity title\": \"<entity_name>\",\n",
    "#       \"entity salience\": \"<0 or 1>\"\n",
    "#     }},\n",
    "#     ...\n",
    "#   ]\n",
    "# }}\n",
    "\n",
    "# Now, based on the article above, return only the final JSON output (with no extra commentary).\n",
    "# '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d504ff1-23c6-4122-b031-c4755c182156",
   "metadata": {},
   "source": [
    "## Few-shot prompt with CoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "617e2724-85ac-42cc-9616-2061a79ab8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_CoT_prompt = f'''\n",
    "Given an article's title and its text, your task is to extract the entities mentioned in the article and assign a salience score to each entity.\n",
    "\n",
    "Below are two examples:\n",
    "\n",
    "Example 1:\n",
    "---------------------\n",
    "Article Title: Laws allowing same sex marriage in Washington, D.C. go into effect\n",
    "Article Text: The United States capital of Washington, D.C. legalized same-sex marriage on Wednesday. Beginning at 6 A.M. local time (1100 UTC), couples began submitting marriage applications at local courthouses citywide. Washington D.C. becomes the seventh United States territory to legalize same sex marriage. The bill was ratified by Mayor Adrian Fenty last December. Due to city's territorial status as a federal district, the bill had to be reviewed by congress. The bill passed congressional review Tuesday night. The bill faced opposition from many family values activists, who tried to stop the bill from becoming law. Supreme Court Chief Justice John Roberts rejected a lawsuit to prevent the measure.\n",
    "Final JSON Output:\n",
    "{{\n",
    "  \"entities\": [\n",
    "    {{\n",
    "      \"entity title\": \"United States\",\n",
    "      \"entity salience\": \"1\"\n",
    "    }},\n",
    "    {{\n",
    "      \"entity title\": \"Washington, D.C.\",\n",
    "      \"entity salience\": \"1\"\n",
    "    }},\n",
    "    {{\n",
    "      \"entity title\": \"same-sex marriage\",\n",
    "      \"entity salience\": \"0\"\n",
    "    }},\n",
    "    {{\n",
    "      \"entity title\": \"Adrian Fenty\",\n",
    "      \"entity salience\": \"0\"\n",
    "    }},\n",
    "    {{\n",
    "      \"entity title\": \"federal district\",\n",
    "      \"entity salience\": \"0\"\n",
    "    }},\n",
    "    {{\n",
    "      \"entity title\": \"family values\",\n",
    "      \"entity salience\": \"0\"\n",
    "    }},\n",
    "    {{\n",
    "      \"entity title\": \"John Roberts\",\n",
    "      \"entity salience\": \"0\"\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "---------------------\n",
    "\n",
    "Example 2:\n",
    "---------------------\n",
    "Article Title: New York Representative Eric Massa to retire\n",
    "Article Text: New York Representative Eric Massa announced Wednesday that he would be stepping down as Congressman from New York's 29th congressional district. He cited health reasons for the sudden announcement. Massa is the latest in a string of United States Congresspeople to resign or not to seek reelection in 2010. He said that he had his third non-specific cancer recurrence in December 2009. He implied that his cancer is terminal, saying “I will now enter the final phase of my life at a more controlled pace.” He denied claims that his resignation is related to a sexual harassment accusation from a male aide. He said that this was untrue, although he admitted to using so called salty language.\n",
    "Final JSON Output:\n",
    "{{\n",
    "  \"entities\": [\n",
    "    {{\n",
    "      \"entity title\": \"New York\",\n",
    "      \"entity salience\": \"1\"\n",
    "    }},\n",
    "    {{\n",
    "      \"entity title\": \"Eric Massa\",\n",
    "      \"entity salience\": \"0\"\n",
    "    }},\n",
    "    {{\n",
    "      \"entity title\": \"Congressman\",\n",
    "      \"entity salience\": \"1\"\n",
    "    }},\n",
    "    {{\n",
    "      \"entity title\": \"New York\",\n",
    "      \"entity salience\": \"1\"\n",
    "    }},\n",
    "    {{\n",
    "      \"entity title\": \"29th congressional district\",\n",
    "      \"entity salience\": \"0\"\n",
    "    }},\n",
    "    {{\n",
    "      \"entity title\": \"United States\",\n",
    "      \"entity salience\": \"1\"\n",
    "    }},\n",
    "    {{\n",
    "      \"entity title\": \"sexual harassment\",\n",
    "      \"entity salience\": \"0\"\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "---------------------\n",
    "\n",
    "Now, use the following chain-of-thought (CoT) instructions:\n",
    "\n",
    "Before producing the final JSON output, think through your reasoning for each extracted entity:\n",
    "- Identify each entity mentioned explicitly in the article.\n",
    "- For each entity, decide if it is central (salience \"1\") or merely mentioned (salience \"0\") based solely on the provided title and text.\n",
    "- Explain your reasoning briefly in your mind (or as intermediate steps), but do not include these explanations in your final answer.\n",
    "\n",
    "Finally, after your internal chain-of-thought reasoning, output only the final JSON output (with no extra commentary) exactly in the format below:\n",
    "\n",
    "{{\n",
    "  \"entities\": [\n",
    "    {{\n",
    "      \"entity title\": \"<entity_name>\",\n",
    "      \"entity salience\": \"<0 or 1>\"\n",
    "    }},\n",
    "    ...\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Now, based on the article below, perform your reasoning and then return only the final JSON answer.\n",
    "\n",
    "---------------------\n",
    "Article Title: {title}\n",
    "Article Text: {article}\n",
    "---------------------\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e2674ca-a18c-4c0c-aa15-62b01034f9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an expert news article analysis assistant. The salience of an entity provides information about the importance or the centrality of that entity to the article text.\"},\n",
    "    {\"role\": \"user\", \"content\": few_shot_CoT_prompt}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "980bfece-476a-4885-8ebc-eba50b9c5da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mapply_chat_template(messages, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m generated_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m response \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(generated_ids, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/intro/lib/python3.9/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/intro/lib/python3.9/site-packages/transformers/generation/utils.py:2223\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2215\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2216\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2217\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2218\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2219\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2220\u001b[0m     )\n\u001b[1;32m   2222\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2223\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2224\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2228\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2230\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2231\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2233\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2234\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2235\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2236\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2237\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2242\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2243\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/intro/lib/python3.9/site-packages/transformers/generation/utils.py:3211\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3208\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m   3210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_prefill:\n\u001b[0;32m-> 3211\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3212\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   3213\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/intro/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/intro/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/intro/lib/python3.9/site-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/intro/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py:842\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m    841\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 842\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    856\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    857\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/intro/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/intro/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/intro/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py:550\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    547\u001b[0m     use_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 550\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mand\u001b[39;00m past_key_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    553\u001b[0m     past_key_values \u001b[38;5;241m=\u001b[39m DynamicCache()\n",
      "File \u001b[0;32m~/.conda/envs/intro/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/intro/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/intro/lib/python3.9/site-packages/torch/nn/modules/sparse.py:190\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/intro/lib/python3.9/site-packages/torch/nn/functional.py:2551\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2545\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2546\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2547\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2548\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2549\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2550\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)"
     ]
    }
   ],
   "source": [
    "model_inputs = tokenizer.apply_chat_template(messages, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "generated_ids = model.generate(model_inputs, max_new_tokens=1000, do_sample=True)\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e94359ed-0544-4fb1-a656-56a411955a08",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresponse\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'response' is not defined"
     ]
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "214bd7b9-36eb-4241-8175-0d5b389af153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"entities\": [\n",
      "    {\n",
      "      \"entity title\": \"US\",\n",
      "      \"entity salience\": \"1\"\n",
      "    },\n",
      "    {\n",
      "      \"entity title\": \"John F. Kennedy International Airport\",\n",
      "      \"entity salience\": \"1\"\n",
      "    },\n",
      "    {\n",
      "      \"entity title\": \"FAA\",\n",
      "      \"entity salience\": \"1\"\n",
      "    },\n",
      "    {\n",
      "      \"entity title\": \"aviation authority\",\n",
      "      \"entity salience\": \"0\"\n",
      "    },\n",
      "    {\n",
      "      \"entity title\": \"New York\",\n",
      "      \"entity salience\": \"1\"\n",
      "    },\n",
      "    {\n",
      "      \"entity title\": \"air traffic controller\",\n",
      "      \"entity salience\": \"1\"\n",
      "    },\n",
      "    {\n",
      "      \"entity title\": \"child\",\n",
      "      \"entity salience\": \"1\"\n",
      "    },\n",
      "    {\n",
      "      \"entity title\": \"pilots\",\n",
      "      \"entity salience\": \"1\"\n",
      "    },\n",
      "    {\n",
      "      \"entity title\": \"National Air Traffic Controllers Association\",\n",
      "      \"entity salience\": \"0\"\n",
      "    },\n",
      "    {\n",
      "      \"entity title\": \"LiveATC.net\",\n",
      "      \"entity salience\": \"0\"\n",
      "    },\n",
      "    {\n",
      "      \"entity title\": \"Dave Pascoe\",\n",
      "      \"entity salience\": \"0\"\n",
      "    }\n"
     ]
    }
   ],
   "source": [
    "decoded_output = '''\n",
    "{\\n  \"entities\": [\\n    {\\n      \"entity title\": \"US\",\\n      \"entity salience\": \"1\"\\n    },\\n    {\\n      \"entity title\": \"John F. Kennedy International Airport\",\\n      \"entity salience\": \"1\"\\n    },\\n    {\\n      \"entity title\": \"FAA\",\\n      \"entity salience\": \"1\"\\n    },\\n    {\\n      \"entity title\": \"aviation authority\",\\n      \"entity salience\": \"0\"\\n    },\\n    {\\n      \"entity title\": \"New York\",\\n      \"entity salience\": \"1\"\\n    },\\n    {\\n      \"entity title\": \"air traffic controller\",\\n      \"entity salience\": \"1\"\\n    },\\n    {\\n      \"entity title\": \"child\",\\n      \"entity salience\": \"1\"\\n    },\\n    {\\n      \"entity title\": \"pilots\",\\n      \"entity salience\": \"1\"\\n    },\\n    {\\n      \"entity title\": \"National Air Traffic Controllers Association\",\\n      \"entity salience\": \"0\"\\n    },\\n    {\\n      \"entity title\": \"LiveATC.net\",\\n      \"entity salience\": \"0\"\\n    },\\n    {\\n      \"entity title\": \"Dave Pascoe\",\\n      \"entity salience\": \"0\"\\n    }\n",
    "'''\n",
    "\n",
    "json_start = decoded_output.find('{')\n",
    "json_end = decoded_output.rfind('}') + 1  # +1 to include the \"}\" in the slice\n",
    "# bt\n",
    "# Slice the decoded output to get the final JSON\n",
    "final_json_output = decoded_output[json_start:json_end].strip()\n",
    "\n",
    "print(final_json_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bc9f66-3de4-4b82-8dfa-feca64667322",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_paths = ['/datasets/ai/llama3/hub/models--meta-llama--Llama-3.2-1B-Instruct/snapshots/9213176726f574b556790deb65791e0c5aa438b6',\n",
    "               'datasets/ai/deepseek/hub/models--deepseek-ai--DeepSeek-R1-Distill-Qwen-1.5B/snapshots/530ca3e1ad39d440e182c2e4317aa40f012512fa',\n",
    "               'datasets/ai/t5/models--google--t5-v1_1-base/snapshots/b5fc947a416ea3cb079532cb3c2bbadeb7f800fc'\n",
    "              ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec8021b-53d0-405a-9504-dd955984bb8a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Loop over entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b994ef33-afca-4a96-9b35-3052563c8168",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Cleans incomplete JSON response by:\n",
    "    1. Extracting the valid JSON part.\n",
    "    2. Removing incomplete entity objects.\n",
    "    3. Returning a properly formatted JSON dictionary.\n",
    "    4. Removes repeated entity titles in the dictionary.\n",
    "\"\"\"\n",
    "def clean_incomplete_json(response):\n",
    " \n",
    "    match = re.search(r'\\{.*\\}', response, re.DOTALL)\n",
    "    if not match:\n",
    "        raise ValueError(\"No valid JSON-like content found in the response.\")\n",
    "\n",
    "    json_like_str = match.group(0)\n",
    "\n",
    "\n",
    "    json_like_str = json_like_str.replace(\"'\", '\"')  # Ensure valid JSON quotes\n",
    "    json_like_str = re.sub(r',\\s*}', '}', json_like_str)  # Remove trailing commas before }\n",
    "    json_like_str = re.sub(r',\\s*\\]', ']', json_like_str)  # Remove trailing commas before ]\n",
    "\n",
    "   \n",
    "    entities_match = re.search(r'\"entities\":\\s*\\[(.*)', json_like_str, re.DOTALL)\n",
    "    if not entities_match:\n",
    "        raise ValueError(\"No 'entities' key found in the response.\")\n",
    "\n",
    "    entities_str = entities_match.group(1).strip()\n",
    "\n",
    "   \n",
    "    entity_blocks = re.findall(r'\\{[^{}]*\\}', entities_str, re.DOTALL)\n",
    "\n",
    "    valid_entities = []\n",
    "    for block in entity_blocks:\n",
    "        try:\n",
    "            entity = json.loads(block)  # Attempt to parse each block\n",
    "            valid_entities.append(entity)  # Keep valid entities\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Skipping invalid entity: {block}\")  # Debugging output\n",
    "\n",
    "   \n",
    "    cleaned_response = {\"entities\": valid_entities}\n",
    "     \n",
    "    cleaned_response[\"entities\"] = list({e[\"entity title\"]: e for e in cleaned_response[\"entities\"]}.values())\n",
    "\n",
    "    return cleaned_response\n",
    "def fuzzy_match(title, candidates, threshold=85):\n",
    "    best_match, score = process.extractOne(title, candidates)\n",
    "    return best_match if score >= threshold else None\n",
    "\n",
    "def evaluate_salience(ground_truth, model_output, threshold=85):\n",
    "    gt_dict = {}\n",
    "    for item in ground_truth:\n",
    "        title = item.get('entity title')\n",
    "        salience = item.get('entity salience')\n",
    "\n",
    "        if title:\n",
    "            title = title.lower()\n",
    "            try:\n",
    "                gt_dict[title] = int(salience) if salience is not None else 0\n",
    "            except ValueError:\n",
    "                gt_dict[title] = 0\n",
    "\n",
    "    pred_dict = {}\n",
    "    for item in model_output:\n",
    "        title = item.get('entity title')\n",
    "        salience = item.get('entity salience')\n",
    "\n",
    "        if title:\n",
    "            title = title.lower()\n",
    "            try:\n",
    "                pred_dict[title] = int(salience) if salience is not None else 0\n",
    "            except ValueError:\n",
    "                pred_dict[title] = 0\n",
    "        else:\n",
    "            print(\"Weird data : \",item)\n",
    "\n",
    "    # Apply fuzzy matching for better entity alignment\n",
    "    updated_pred_dict = {}\n",
    "    for pred_title in pred_dict:\n",
    "        matched_title = fuzzy_match(pred_title, list(gt_dict.keys()), threshold)\n",
    "        if matched_title:\n",
    "            updated_pred_dict[matched_title] = pred_dict[pred_title]\n",
    "        else:\n",
    "            updated_pred_dict[pred_title] = pred_dict[pred_title]\n",
    "\n",
    "    all_entities = set(gt_dict.keys()).union(set(updated_pred_dict.keys()))\n",
    "    y_true = [gt_dict.get(entity, 0) for entity in all_entities]\n",
    "    y_pred = [updated_pred_dict.get(entity, 0) for entity in all_entities]\n",
    "\n",
    "    return y_true, y_pred\n",
    "\n",
    "def evaluate_multiple_instances(ground_truths, model_outputs, threshold=85):\n",
    "    all_y_true = []\n",
    "    all_y_pred = []\n",
    "    \n",
    "    for gt, mo in zip(ground_truths, model_outputs):\n",
    "        y_true, y_pred = evaluate_salience(gt, mo, threshold)\n",
    "        all_y_true.extend(y_true)\n",
    "        all_y_pred.extend(y_pred)\n",
    "        \n",
    "    precision = precision_score(all_y_true, all_y_pred, average='macro')\n",
    "    recall = recall_score(all_y_true, all_y_pred, average='macro')\n",
    "    f1 = f1_score(all_y_true, all_y_pred, average='macro')\n",
    "    \n",
    "    # Compute accuracy based on fuzzy-matched salient entities\n",
    "    all_salient_correct = all(\n",
    "        gt_dict.get(entity, 0) == 1 and updated_pred_dict.get(entity, 0) == 1\n",
    "        for gt, mo in zip(ground_truths, model_outputs)\n",
    "        for gt_dict, updated_pred_dict in [\n",
    "            (\n",
    "                {fuzzy_match(item['entity title'].lower(), [x['entity title'].lower() for x in mo], threshold): int(item['entity salience']) for item in gt},\n",
    "                {item['entity title'].lower(): int(item['entity salience']) for item in mo}\n",
    "            )\n",
    "        ]\n",
    "        for entity in gt_dict if gt_dict[entity] == 1\n",
    "    )\n",
    "\n",
    "    accuracy = 1.0 if all_salient_correct else 0.0\n",
    "    \n",
    "    return {\"precision\": precision, \"recall\": recall, \"f1\": f1, \"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f6afcb-d1a0-4e27-a32b-07f4f7aec2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "articles = list(df['text'])\n",
    "titles = list(df['title'])\n",
    "prompt_template = '''\n",
    "Article Title: {title}\n",
    "Article Text: {article}\n",
    "\n",
    "You are an expert news article analysis assistant. Given an article's title and its text, your task is to extract the entities \n",
    "mentioned in the article and assign a salience score to each entity. The salience score is defined as follows:\n",
    "• 1: The entity is central to the article's content.\n",
    "• 0: The entity is mentioned but is not central.\n",
    "\n",
    "Follow these rules:\n",
    "1. Only extract entities that are explicitly mentioned in the article.\n",
    "2. Do not include any entities that do not appear in the article.\n",
    "3. Use only the provided title and text to determine salience.\n",
    "4. Format your answer as valid JSON exactly as specified below.\n",
    "5. Do not infinitely loop on the same words for any of the entity titles.\n",
    "6. Every entity title should appear only once.\n",
    "\n",
    "The expected JSON format is:\n",
    "{{\n",
    "  \"entities\": [\n",
    "    {{\n",
    "      \"entity title\": \"<entity_name>\",\n",
    "      \"entity salience\": \"<0 or 1>\"\n",
    "    }},\n",
    "    ...\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Now, based on the article above, return only the final JSON output (with no extra commentary).\n",
    "'''\n",
    "\n",
    "\n",
    "####RUNS ZERO SHOT FOR EVERY MODEL SPECIFIED IN MODEL PATHS###########\n",
    "i = 0\n",
    "n = 5 #num instances\n",
    "for model_path in model_paths[:1]:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.float16).to(\"cuda\")  # Move model to CUDA\n",
    "    for title,article in zip(titles[:n],articles[:n]):\n",
    "        prompt = prompt_template.format(title=title, article=article)\n",
    "        input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "        \n",
    "        # Generate response\n",
    "        output_ids = model.generate(input_ids, max_new_tokens=1000)\n",
    "\n",
    "        # Decode and print the response\n",
    "        response = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "        \n",
    "        response = response.split(\"Now, based on the article above, return only the final JSON output (with no extra commentary).\")[-1]\n",
    "        result = clean_incomplete_json(response)\n",
    "        print(\"Iteration\", i)\n",
    "        i+=1\n",
    "        outputs.append(result['entities'])\n",
    "\n",
    "f = open('outputs.txt','w+')\n",
    "f.write(str(outputs))\n",
    "f.close()\n",
    "\n",
    "metrics = evaluate_multiple_instances(df['entities'][:n],outputs)\n",
    "print(\"METRICS\",metrics)\n",
    "print(\"\\n\")\n",
    "print(outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "baseline-salient-entities",
   "language": "python",
   "name": "baseline"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
